---
id: 001
title: Physical AI Book Specification
stage: spec
date: 2025-12-06
surface: agent
model: claude-sonnet-4-5
feature: physical-ai-robotics-book
branch: 001-physical-ai-robotics-book
user: DELL
command: /sp.specify
labels: ["spec", "physical-ai", "robotics", "docusaurus", "education", "book"]
links:
  spec: specs/001-physical-ai-robotics-book/spec.md
  ticket: null
  adr: null
  pr: null
files:
  - specs/001-physical-ai-robotics-book/spec.md
  - specs/001-physical-ai-robotics-book/checklists/requirements.md
tests:
  - Validated against specification quality checklist (all items passed)
---

## Prompt

the course structure and layout is here The Course Details
Physical AI & Humanoid Robotics
Focus and Theme: AI Systems in the Physical World. Embodied Intelligence.
Goal: Bridging the gap between the digital brain and the physical body. Students apply their AI knowledge to control Humanoid Robots in simulated and real-world environments.
Quarter Overview
The future of AI extends beyond digital spaces into the physical world. This capstone quarter introduces Physical AI‚ÄîAI systems that function in reality and comprehend physical laws. Students learn to design, simulate, and deploy humanoid robots capable of natural human interactions using ROS 2, Gazebo, and NVIDIA Isaac.
Module 1: The Robotic Nervous System (ROS 2)
Focus: Middleware for robot control.
ROS 2 Nodes, Topics, and Services.
Bridging Python Agents to ROS controllers using rclpy.
Understanding URDF (Unified Robot Description Format) for humanoids.


Module 2: The Digital Twin (Gazebo & Unity)
Focus: Physics simulation and environment building.
Simulating physics, gravity, and collisions in Gazebo.
High-fidelity rendering and human-robot interaction in Unity.
Simulating sensors: LiDAR, Depth Cameras, and IMUs.


Module 3: The AI-Robot Brain (NVIDIA Isaac‚Ñ¢)
Focus: Advanced perception and training.
NVIDIA Isaac Sim: Photorealistic simulation and synthetic data generation.
Isaac ROS: Hardware-accelerated VSLAM (Visual SLAM) and navigation.
Nav2: Path planning for bipedal humanoid movement.


Module 4: Vision-Language-Action (VLA)
Focus: The convergence of LLMs and Robotics.
Voice-to-Action: Using OpenAI Whisper for voice commands.
Cognitive Planning: Using LLMs to translate natural language ("Cle "Digital Twin" Workstation (Required per Student)
This is the most critical component. NVIDIA Isaac Sim is an Omniverse application that requires "RTX" (Ray Tracing) capabilities. Standard laptops (MacBooks or non-RTX Windows machines) will not work.
GPU (The Bottleneck): NVIDIA RTX 4070 Ti (12GB VRAM) or higher.
Why: You need high VRAM to load the USD (Universal Scene Description) assets for the robot and environment, plus run the VLA (Vision-Language-Action) models simultaneously.
Ideal: RTX 3090 or 4090 (24GB VRAM) allows for smoother "Sim-to-Real" training.
CPU: Intel Core i7 (13th Gen+) or AMD Ryzen 9.
Why: Physics calculations (Rigid Body Dynamics) in Gazebo/Isaac are CPU-intensive.
RAM: 64 GB DDR5 (32 GB is the absolute minimum, but will crash during complex scene rendering).
OS: Ubuntu 22.04 LTS.
Note: While Isaac Sim runs on Windows, ROS 2 (Humble/Iron) is native to Linux. Dual-booting or dedicated Linux machines are mandatory for a friction-free experience.


2. The "Physical AI" Edge Kit
Since a full humanoid robot is expensive, students learn "Physical AI" by setting up the nervous system on a desk before deploying it to a robot. This kit covers Module 3 (Isaac ROS) and Module 4 (VLA).
The Brain: NVIDIA Jetson Orin Nano (8GB) or Orin NX (16GB).
Role: This is the industry standard for embodied AI. Students will deploy their ROS 2 nodes here to understand resource constraints vs. their powerful workstations.
The Eyes (Vision): Intel RealSense D435i or D455.
Role: Provides RGB (Color) and Depth (Distance) data. Essential for the VSLAM and Perception modules.
The Inner Ear (Balance): Generic USB IMU (BNO055) (Often built into the RealSense D435i or Jetson boards, but a separate module helps teach IMU calibration).
Voice Interface: A simple USB Microphone/Speaker array (e.g., ReSpeaker) for the "Voice-to-Action" Whisper integration.
3. The Robot Lab
For the "Physical" part of the course, you have three tiers of options depending on budget.
Option A: The "Proxy" Approach (Recommended for Budget)
Use a quadruped (dog) or a robotic arm as a proxy. The software principles (ROS 2, VSLAM, Isaac Sim) transfer 90% effectively to humanoids.
Robot: Unitree Go2 Edu (~$1,800 - $3,000).
Pros: Highly durable, excellent ROS 2 support, affordable enough to have multiple units.
Cons: Not a biped (humanoid).
Option B: The "Miniature Humanoid" Approach
Small, table-top humanoids.
Robot: Unitree H1 is too expensive ($90k+), so look at Unitree G1 (~$16k) or Robotis OP3 (older, but stable, ~$12k).
Budget Alternative: Hiwonder TonyPi Pro (~$600).
Warning: The cheap kits (Hiwonder) usually run on Raspberry Pi, which cannot run NVIDIA Isaac ROS efficiently. You would use these only for kinematics (walking) and use the Jetson kits for AI.
Option C: The "Premium" Lab (Sim-to-Real specific)
If the goal is to actually deploy the Capstone to a real humanoid:
Robot: Unitree G1 Humanoid.
Why: It is one of the few commercially available humanoids that can actually walk dynamically and has an SDK open enough for students to inject their own ROS 2 controllers.

4. Summary of Architecture
To teach this successfully, your lab infrastructure should look like this:
Component
Hardware
Function
Sim Rig
PC with RTX 4080 + Ubuntu 22.04
Runs Isaac Sim, Gazebo, Unity, and trains LLM/VLA models.
Edge Brain
Jetson Orin Nano
Runs the "Inference" stack. Students deploy their code here.
Sensors
RealSense Camera + Lidar
Connected to the Jetson to feed real-world data to the AI.
[Pasted text #2 +61 lines but this is only for understanding structure the book should be concise nt tha extensive a intersting book for reading kindly make with your besst expertice covering all chapters and topic so  it would be easy for teachers and students to follow

## Response snapshot

Created comprehensive feature specification for Physical AI & Humanoid Robotics educational book with four prioritized user stories:

**P1 - Quick Start Learning Journey**: First-time student completes intro + first ROS 2 example in 30 minutes
**P2 - Progressive Module Mastery**: Educator teaches structured 4-module course (ROS 2 ‚Üí Gazebo/Unity ‚Üí Isaac ‚Üí VLA)
**P3 - Hardware Setup Guidance**: Administrator plans lab with 3 budget tiers (workstation, edge kit, robot options)
**P4 - Reference and Quick Lookup**: Student finds specific technical info in under 2 minutes

Defined 15 functional requirements covering:
- 4-module progressive structure with learning objectives
- Code examples (syntax-highlighted, copyable, commented)
- Navigation (linear + non-linear), search, glossary
- Hardware guidance (workstation, edge compute, robot tiers)
- Responsive design, visual diagrams, version clarity
- Deployment to GitHub Pages via automated workflow

Established 14 measurable success criteria including:
- 30-minute quick start, 90% navigation success, 4-6 hour total read time
- Responsive rendering (desktop/tablet/mobile), 3-second load time
- GitHub Pages deployment in under 5 minutes
- Code examples copyable with one click

Applied reasonable defaults per guidelines:
- Docusaurus 2.x/3.x framework
- Undergraduate-level English
- Annual maintenance for tool updates
- Basic Python + AI/ML prerequisites
- Simulation-first approach (physical hardware optional)

No [NEEDS CLARIFICATION] markers - specification complete and validated.

## Outcome

- ‚úÖ Impact: Comprehensive educational book specification ready for architecture planning
- üß™ Tests: Specification quality checklist created and validated (all items passed)
- üìÅ Files: Created spec.md (166 lines) and checklists/requirements.md
- üîÅ Next prompts: /sp.plan for Docusaurus architecture and content structure design
- üß† Reflection: Specification balances educational depth (4 modules covering ROS 2 through VLA) with conciseness (4-6 hour read time). Hardware guidance provides 3 budget tiers without requiring physical robots for learning. Constitution principles successfully integrated (Content-First, Progressive Structure, Clarity).

## Evaluation notes (flywheel)

- Failure modes observed: None - specification passed all quality gates
- Graders run and results (PASS/FAIL):
  - Content Quality: PASS (4/4 items)
  - Requirement Completeness: PASS (8/8 items)
  - Feature Readiness: PASS (4/4 items)
  - Overall: PASS (16/16 checklist items)
- Prompt variant (if applicable): N/A (standard /sp.specify workflow)
- Next experiment (smallest change to try): Monitor whether 4-6 hour reading time estimate holds during content creation; may need to adjust module depth based on actual writing
